{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4cOW8k_u-Vj"
   },
   "source": [
    "$$ \\text{Food 101} $$\n",
    "_________\n",
    "\n",
    "We will be exploring a food classification problem. We will use a convolutional neural network backbone and a fully connected head with a single hidden layer as a classifier.\n",
    "\n",
    "| SoTAs |\n",
    "|-------|\n",
    "\n",
    "| Model | Augmentations | Crops | Epochs | Additional Notes | Top-1 Accuracy % | Top-5 Accuracy % |\n",
    "|-------|---------------|-------|--------|------------------|------------------|------------------|\n",
    "|Inception V3 | Flip, Rotation, Color, Zoom | 10 crops for validation | 32 | Manually doing transformations and crops during validation | 88.28 | 96.88 |\n",
    "|WISeR | Flip, Rotation, Color, Zoom | 10 crops for validation | ~32 | Ensemble of Residual and Slice Network | 90.27 | 98.71 |\n",
    "|ResNet50 + fastai | Optimal transformations | Test time augmentations | 16 | Using a size of 512 only for later epochs | 90.52 | 98.34 |\n",
    "\n",
    "_____________\n",
    "\n",
    "| Dataset Attributes|  \n",
    "|---------|\n",
    "| 101 food categories |\n",
    "| 101,000 images |\n",
    "| 250 test images, 750 training images per class.|\n",
    "| Training images were not cleaned. |\n",
    "| Images were rescaled to have max sidelength of 512 pixels. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBIads-Zu-Vm"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TwwgxVXu-Vv"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXsuPgsHu-Vx"
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "model = models.resnet50 # Residual neural net\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.FOOD)\n",
    "path_img = path/'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Train/Test Split |\n",
    "|------------------|\n",
    "| Train: 60,600 images |  \n",
    "| Val  : 15,150 images |  \n",
    "| Test : 25,250 images |  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyOAoQRAu-V5"
   },
   "outputs": [],
   "source": [
    "train_path = path/'train.txt'\n",
    "test_path = path/'test.txt'\n",
    "\n",
    "def file_df(path):\n",
    "    '''\n",
    "    Pandas dataframe from csv. \n",
    "    Place images into dataframe. \n",
    "    '''\n",
    "    df = pd.read_csv(path, delimiter='/', header=None, names=['label', 'name'])\n",
    "    df['name'] =  df['label'].astype(str) + \"/\" + df['name'].astype(str) + \".jpg\"\n",
    "    return df\n",
    "\n",
    "train_df = file_df(train_path)\n",
    "test_df = file_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df=train_df, path=path/'images', cols=1)\n",
    "        .split_by_rand_pct(0.2)\n",
    "        .label_from_df(cols=0)\n",
    "        .transform(tfms=get_transforms(), size=224)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of the primary transformations used by fastai. Note that the two main things we can change are the degree to which an item will receive a transformation and the degree to how much the random selected range will vary.\n",
    "\n",
    "Note that the transform method returns a tuple of two lists of transforms; one training + one validation. The second list is limited to resizing. \n",
    "\n",
    "| Default Transforms |\n",
    "|----------|\n",
    "\n",
    "|  type    |  params   | probability |\n",
    "|----------|-----------|-------------|\n",
    "| crop_pad       | row_pct(0, 1) : col_pct(0, 1) : padding_mode(reflection) | 1.0 |\n",
    "| flip_lr        |  na | 0.5 |\n",
    "| symmetric_warp | magnitude(-0.2, 0.2) | 0.75 |\n",
    "| rotate         | degrees(-10.0, 10.0) | 0.75 |\n",
    "| zoom           | scale(1.0, 1.1), row_pct(0, 1), col_pct(0, 1) | 0.75 |\n",
    "| brightness     | change(0.4, 0.6) | 0.75 |\n",
    "| contrast       | scale(0.8, 1.25) | 0.75 |\n",
    "| crop_pad       | na | 1.0 |\n",
    "\n",
    "$\\text{}$\n",
    "$\\text{}$\n",
    "\n",
    "| Secondary Transformations |\n",
    "|-------------------------|\n",
    "| jitter, skew, squish |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zSe_rgdu-V7",
    "outputId": "f709db7d-9d14-48af-9528-7793c0cd59f0"
   },
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(10, 10)) # visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74QKDJ8Lu-V-"
   },
   "source": [
    "$$ \\text{Original Image} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHzV2qu1u-V_",
    "outputId": "780ebf52-bf21-42ee-b0ea-5d0bbb34b404"
   },
   "outputs": [],
   "source": [
    "img = open_image(path/'images'/'baklava'/'1006121.jpg') # Example single image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Example Transformations Applied} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBZtWdb2u-WA",
    "outputId": "1f575c69-824c-43bf-9715-7725dc076ab7"
   },
   "outputs": [],
   "source": [
    "# Example transformations\n",
    "[img.apply_tfms(get_transforms()[0]).show(ax=ax) for i,ax in enumerate(plt.subplots(1, 5, figsize=(16, 8))[1].flatten())];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6o-Grh_Pu-WC"
   },
   "source": [
    "$$ \\text{Classes & Class Count} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48DxjAfru-WD",
    "outputId": "d9b84395-43f5-43fb-a51f-2aa2f800f088"
   },
   "outputs": [],
   "source": [
    "print(data.classes); print(data.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Metrics} $$\n",
    "\n",
    "$$ \\text{Top N Accuracy : measures how often predicted class falls in top N values.} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtD0Rz5qu-WF"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, model, metrics=accuracy, callback_fns=ShowGraph) # Top 1 accuracy == traditional accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy9pgKlmu-WH"
   },
   "source": [
    "$$ \\text{Optimal Learning Rate} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6i9fYwmu-WI",
    "outputId": "2a3fd986-b4fc-4810-d0b2-907245be8c0e"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Wgw-14_u-WL"
   },
   "source": [
    "By changing the learning rate every n epochs we can better work with how fast our model is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESnqpboGu-WM",
    "outputId": "3fd3d211-d2f2-4c86-80ed-d438093b95fc"
   },
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "learn.fit_one_cycle(5, slice(lr))\n",
    "learn.save('food101-test-5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_Yt2u_Lu-WO"
   },
   "source": [
    "### Unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8J0uGjRu-WO",
    "outputId": "23e1256c-f75d-4a15-8028-2c37d8836a66"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKfaylJZu-WQ",
    "outputId": "21b39ae9-9922-426a-93bd-2e37f003669f"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=slice(1e-5, 1e-3))\n",
    "learn.save('food101-test-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENenF-DRu-WS",
    "outputId": "f9323cc2-49d4-4850-cad9-8113599410d6"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=slice(1e-6, 1e-3))\n",
    "learn.save('food-101-test-e15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DPaovLqu-WW",
    "outputId": "9f56c660-7c0b-4daa-b444-d65cea2557e3"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=slice(1e-6, 1e-3))\n",
    "learn.save('food-101-test-e20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKn7669Iu-WZ"
   },
   "source": [
    "Let's switch to 512 to try increasing the accuracy. From what I understand Fastai resizes the images so that they're squared. By resizing the image to 512, there may be white space added to some of the images because not all images are already squared. \n",
    "\n",
    "I'm not sure if progressive image resizing works because the act of increasing the size of image is somewhat similar to the neural nets behavior of learning progressively higher features or if it's just because the neural net is getting more information. I tested the model with a smaller sized starting image, i.e. 64x64 and this was too small for the image to pick up significant features. This logic seems to be similar to superpixeling. \n",
    "\n",
    "Note that the size can be rectangle if you specify it. \n",
    "\n",
    "Note after certain transforms, there will be missing pixels. Those can be set as black, the value of the pixel to the nearest border, or the value of the pixel symmetric to the nearest border. Here we have it set as the default which I believe is black. \n",
    "\n",
    "Note there are 3 methods of resizing: ResizeMethod.CROP, ResizeMethod.PAD, ResizeMethod.SQUISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ef9tghy2u-Wa",
    "outputId": "14e89e84-6a44-4253-c435-21b0ed8e37c2"
   },
   "outputs": [],
   "source": [
    "bs=24\n",
    "\n",
    "data = (ImageList.from_df(df=train_df, path=path/'images', cols=1)\n",
    "        .split_by_rand_pct(0.2)\n",
    "        .label_from_df(cols=0)\n",
    "        .transform(tfms=get_transforms(), size=512, padding_mode='border')\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "learn = cnn_learner(data, model, metrics=accuracy, callback_fns=ShowGraph)\n",
    "learn.load('food-101-test-e20');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ju6W_hru-Wc",
    "outputId": "60d75d2e-8bd0-4eea-9903-5f58cf5d41b0"
   },
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(5, max_lr=slice(1e-7, 1e-2))\n",
    "# learn.save('food101-test-15-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 2.29E-06\n",
      "Min loss divided by 10: 2.29E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sii2oRxJu-Wd",
    "outputId": "efddbc10-e84f-4211-d6ad-15c5abaa7c89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='256' class='' max='2525', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.14% [256/2525 07:39<1:07:55 1.1911]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, max_lr=slice(1e-6, 1e-2))\n",
    "learn.save('food101-test-22-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRS-L0TXu-Wf",
    "outputId": "2c1a6d75-2a3c-4091-a3d9-4256b63428b9"
   },
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(2, max_lr=slice(1e-9, 1e-4))\n",
    "# learn.save('food101-test-25-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PzeO6yY3u-Wh",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aa7f7b70a42b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationInterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36m_cl_int_from_learner\u001b[0;34m(cls, learn, ds_type, activ, tta)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cl_int_from_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactiv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;34m\"Create an instance of `ClassificationInterpretation`. `tta` indicates if we want to use Test Time Augmentation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtta\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactiv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_type, activ, with_loss, n_batch, pbar)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(callbacks),\n\u001b[0;32m--> 339\u001b[0;31m                          activ=activ, loss_func=lf, n_batch=n_batch, pbar=pbar)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     def pred_batch(self, ds_type:DatasetType=DatasetType.Valid, batch:Tuple=None, reconstruct:bool=False,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m\"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     res = [to_float(torch.cat(o).cpu()) for o in\n\u001b[0;32m---> 44\u001b[0;31m            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNoneReduceOnCPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mto_detach\u001b[0;34m(b, cpu)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mItemsList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/core.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfirst_el\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(x, cpu)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Klv5RA3u-Wi",
    "outputId": "13736cf5-a3fc-49a3-d008-96d4da6d9b79"
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfX7HxU4u-Wk",
    "outputId": "f3a9eb90-8725-4298-c087-0d3b03b697f7"
   },
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4HCLckSu-Wm",
    "outputId": "a8400ab0-d7d1-4068-98e1-ae52bd25d9fe"
   },
   "outputs": [],
   "source": [
    "interp.plot_multi_top_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-CBKTmIu-Wo",
    "outputId": "b21ae96e-30eb-4be2-8e2f-d8b9d2bf3bbd"
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(20, 20), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KscrrtHzu-Wq"
   },
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B04Jftpru-Wq",
    "outputId": "ef2a694c-5762-4b2c-dc97-5c28ad8d5445"
   },
   "outputs": [],
   "source": [
    "bs=24\n",
    "test_data = (ImageList.from_df(df=test_df, path=path/'images', cols=1)\n",
    "            .split_none()\n",
    "            .label_from_df(cols=0)\n",
    "            .transform(size=512)\n",
    "            .databunch(bs=bs)\n",
    "            .normalize(imagenet_stats))\n",
    "\n",
    "learn = cnn_learner(test_data, model, metrics=accuracy, callback_fns=ShowGraph)\n",
    "learn.load('food101-test-20-512');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional option to improve our model is TTA.\n",
    "\n",
    "- TTA(Time tested augmentation): \n",
    "    - Create multiple augmented copies of each image in the test set. The model will make a prediction for each set, then return an ensemble of those predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.55672616, tensor(0.8435)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate(test_data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_preds, y = learn.TTA()\n",
    "# accuracy(log_preds, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ug4MgtcKu-Wu"
   },
   "source": [
    "The next step for me would be to slightly increase the variance of some of the available transformations, I believe that the model will learn more quickly and become more robust. -- after some experimentation. \n",
    "\n",
    "Note that our model struggles with fine grained differences.\n",
    "\n",
    "The other main area that I would focus on is to fix the mislabeled images, then to view additional options for helping with fine grained differences.  \n",
    "\n",
    "As we go through our model it's important to get to know the data, and checking on the data intermittently throughout the training process is how we know what is working. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "food-101.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
